# Stochastic-Optimization-in-R

Project: Implementation of stochastic algorithms with hyper-parameter tuning and efficiency analysis based on small and large datasets.

Algorithms implemented
- Stochastic Gradient Descent (SGD)
- Stochastic Gradient Descent with Momentum (MSGD)
- Stochastic Gradient Descent with Nesterov Accelerated Gradient (NAGSGD)
- Adaptive Gradient Algorithm (AdaGrad)
- Root Mean Square Propagation (RMSProp) 
- Adaptive Moment Estimation (Adam)

Involved data sets
- Question 1: simulated data (n=1000) with 1 feature 
- Question 2: weather data (n=96453) with 5 features 

# Change 1

## change 1.1

